{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93700d41",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "eP9VcOVoebew"
   },
   "source": [
    "# OpenCV fundamentals\n",
    "\n",
    "This notebook covers opening files, looking at pixels, and some simple image processing techniques.\n",
    "\n",
    "We'll use the following sample image, stolen from the Internet. But you can use whatever image you like.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226d6d54",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "cIU7W8Wmebey"
   },
   "source": [
    "## Python getting started\n",
    "\n",
    "First we need to import the relevant libraries: OpenCV itself, Numpy, and a couple of others. Common and Video are simple data handling and opening routines that you can find in the OpenCV Python Samples directory or from the github repo linked above.  We'll start each notebook with the same includes - you don't need all of them every time (so this is bad form, really) but it's easier to just copy and paste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2fe6112",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "TXKxw8iJebez"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# These imports let you use opencv\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m \u001b[38;5;66;03m#opencv itself\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \u001b[38;5;66;03m# matrix manipulations\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#the following are to do with this interactive notebook code\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# These imports let you use opencv\n",
    "import cv2 #opencv itself\n",
    "\n",
    "import numpy as np # matrix manipulations\n",
    "\n",
    "#the following are to do with this interactive notebook code\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt # this lets you draw inline pictures in the notebooks\n",
    "import pylab # this allows you to control figure size \n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0) # this controls figure size in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4b82bd",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "htK6mm-Gebe2"
   },
   "source": [
    "Now we can open an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce9034ce",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "Ah762ATHebe3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m input_image\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mme.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "input_image=cv2.imread(r\"me.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9453d175",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "ut1_Lwdgebe5"
   },
   "source": [
    "We can find out various things about that image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09344b34",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "awdTYn4Gebe6",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43minput_image\u001b[49m\u001b[38;5;241m.\u001b[39msize)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_image' is not defined"
     ]
    }
   ],
   "source": [
    "print(input_image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "060b62cf",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "af7iQyhqebe8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43minput_image\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_image' is not defined"
     ]
    }
   ],
   "source": [
    "print(input_image.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebeea95b",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "UhxrodZrebe_"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43minput_image\u001b[49m\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_image' is not defined"
     ]
    }
   ],
   "source": [
    "print(input_image.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab076d02",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "stSDqhuBebfA"
   },
   "source": [
    "**gotcha** that last one (datatype) is one of the tricky things about working in Python. As it's not strongly typed, Python will allow you to have arrays of different types but the same size, and some functions will return arrays of types that you probably don't want. Being able to check and inspect the datatype like this is very useful and is one of the things I often find myself doing in debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b5d6d07",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "woP9RhyCebfB",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mimshow(input_image)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(input_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7ad571",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "6VFxWhvUebfD",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "What this illustrates is something key about OpenCV: it doesn't store images in RGB format, but in BGR format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccf4c6f3",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "zgEQX0isebfD"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# split channels\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m b,g,r\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39msplit(input_image)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# show one of the channels (this is red - see that the sky is kind of dark. try changing it to b)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(r, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrey\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# split channels\n",
    "b,g,r=cv2.split(input_image)\n",
    "# show one of the channels (this is red - see that the sky is kind of dark. try changing it to b)\n",
    "plt.imshow(r, cmap='grey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc1c1b1",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "XqE1jCKaebfG"
   },
   "source": [
    "## converting between colour spaces, merging and splitting channels\n",
    "\n",
    "We can convert between various colourspaces in OpenCV easily. We've seen how to split, above. We can also merge channels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "782f9f41",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "Ev_3hJKLebfH"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m merged\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mmerge([r,g,b])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# merge takes an array of single channel matrices\u001b[39;00m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(merged)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "merged=cv2.merge([r,g,b])\n",
    "# merge takes an array of single channel matrices\n",
    "plt.imshow(merged)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c79beab",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "cJ-UCAynebfJ"
   },
   "source": [
    "OpenCV also has a function specifically for dealing with image colorspaces, so rather than split and merge channels by hand you can use this instead. It is usually marginally faster...\n",
    "\n",
    "There are something like 250 color related flags in OpenCV for conversion and display. The ones you are most likely to use are COLOR_BGR2RGB for RGB conversion, COLOR_BGR2GRAY for conversion to greyscale, and COLOR_BGR2HSV for conversion to Hue,Saturation,Value colour space. [http://docs.opencv.org/trunk/de/d25/imgproc_color_conversions.html] has more information on how these colour conversions are done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a865dede",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "egPmVUvYebfK"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m COLORflags \u001b[38;5;241m=\u001b[39m [flag \u001b[38;5;28;01mfor\u001b[39;00m flag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m(\u001b[43mcv2\u001b[49m) \u001b[38;5;28;01mif\u001b[39;00m flag\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOLOR\u001b[39m\u001b[38;5;124m'\u001b[39m) ]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(COLORflags))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# If you want to see them all, rather than just a count uncomment the following line\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#print(COLORflags)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "COLORflags = [flag for flag in dir(cv2) if flag.startswith('COLOR') ]\n",
    "print(len(COLORflags))\n",
    "\n",
    "# If you want to see them all, rather than just a count uncomment the following line\n",
    "#print(COLORflags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "794d9653",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "INRZEZdvebfM"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m opencv_merged\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mcvtColor(input_image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(opencv_merged)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "opencv_merged=cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(opencv_merged)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03df828",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "lfo1Lue9ebfN"
   },
   "source": [
    "## Getting image data and setting image data\n",
    "\n",
    "Images in python OpenCV are numpy arrays. Numpy arrays are optimised for fast array operations and so there are usually fast methods for doing array calculations which don't actually involve writing all the detail yourself. So it's usually bad practice to access individual pixels, but you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39da4508",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "32AQVQ0uebfO"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pixel \u001b[38;5;241m=\u001b[39m \u001b[43minput_image\u001b[49m[\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m100\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(pixel)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_image' is not defined"
     ]
    }
   ],
   "source": [
    "pixel = input_image[100,100]\n",
    "print(pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "181d932e",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "OE1vlYo2ebfQ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minput_image\u001b[49m[\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m100\u001b[39m] \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m pixelnew \u001b[38;5;241m=\u001b[39m input_image[\u001b[38;5;241m100\u001b[39m,\u001b[38;5;241m100\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(pixelnew)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_image' is not defined"
     ]
    }
   ],
   "source": [
    "input_image[100,100] = [0,0,0]\n",
    "pixelnew = input_image[100,100]\n",
    "print(pixelnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31de570a",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "KsFd9SBzebfS"
   },
   "source": [
    "## Getting and setting regions of an image\n",
    "\n",
    "In the same way as we can get or set individual pixels, we can get or set regions of an image. This is a particularly useful way to get a region of interest to work on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e957ebb0",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "D0rwsf8sebfS",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m face \u001b[38;5;241m=\u001b[39m \u001b[43minput_image\u001b[49m[\u001b[38;5;241m60\u001b[39m:\u001b[38;5;241m250\u001b[39m, \u001b[38;5;241m70\u001b[39m:\u001b[38;5;241m350\u001b[39m]\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(face)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_image' is not defined"
     ]
    }
   ],
   "source": [
    "face = input_image[60:250, 70:350]\n",
    "plt.imshow(face)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c7abfa",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "bCVZFlDhebfW",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Matrix slicing\n",
    "In OpenCV python style, as I have mentioned, images are numpy arrays. There are some superb array manipulation in numpy tutorials out there: this is a great introduction if you've not done it before [http://www.scipy-lectures.org/intro/numpy/numpy.html#indexing-and-slicing]. The getting and setting of regions above uses slicing, though, and I'd like to finish this notebook with a little more detail on what is going on there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a05d12be",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "9LLhUPE7ebfX",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m freshim2 \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mme.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m crop \u001b[38;5;241m=\u001b[39m freshim2[\u001b[38;5;241m100\u001b[39m:\u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m130\u001b[39m:\u001b[38;5;241m300\u001b[39m] \n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(crop)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "freshim2 = cv2.imread(r\"me.jpg\")\n",
    "crop = freshim2[100:400, 130:300] \n",
    "plt.imshow(crop)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f012c6eb",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "3pURgAtbebfZ"
   },
   "source": [
    "The key thing to note here is that the slicing works like\n",
    "```\n",
    "[top_y:bottom_y, left_x:right_x]\n",
    "```\n",
    "This can also be thought of as \n",
    "```\n",
    "[y:y+height, x:x+width]\n",
    "```\n",
    "\n",
    "You can also use slicing to separate out channels.  In this case you want \n",
    "```\n",
    "[y:y+height, x:x+width, channel]\n",
    "```\n",
    "where channel represents the colour you're interested in - this could be 0 = blue, 1 = green or 2=red if you're dealing with a default OpenCV image, but if you've got an image that has been converted it could be something else. Here's an example that converts to HSV then selects the S (Saturation) channel of the same crop above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37af8116",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "9cSa7WDHebfZ"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hsvim\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mcvtColor(freshim2,cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2HSV)\n\u001b[1;32m      2\u001b[0m bcrop \u001b[38;5;241m=\u001b[39mhsvim[\u001b[38;5;241m100\u001b[39m:\u001b[38;5;241m400\u001b[39m, \u001b[38;5;241m100\u001b[39m:\u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(bcrop, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "hsvim=cv2.cvtColor(freshim2,cv2.COLOR_BGR2HSV)\n",
    "bcrop =hsvim[100:400, 100:300, 1]\n",
    "plt.imshow(bcrop, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bd93d3",
   "metadata": {
    "colab_type": "text",
    "id": "-jEyTpSTebff"
   },
   "source": [
    "[Next](2-Image_stats_and_image_processing.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c651ab",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "2TcCJuat3fWI"
   },
   "source": [
    "# Image stats and image processing\n",
    "This notebook follows on from the fundamentals notebook.\n",
    "\n",
    "This will introduce some simple stats, smoothing, and basic image processing.\n",
    "\n",
    "But first let us include what we need to include and load up our test image.\n",
    "\n",
    "<p>\n",
    " Estimated time needed: <strong>20 min</strong>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57d89830",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "sWiMMUll3fWL"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# these imports let you use opencv\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m \u001b[38;5;66;03m#opencv itself\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \u001b[38;5;66;03m# matrix manipulations\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#the following are to do with this interactive notebook code\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "\n",
    "# these imports let you use opencv\n",
    "import cv2 #opencv itself\n",
    "\n",
    "import numpy as np # matrix manipulations\n",
    "\n",
    "#the following are to do with this interactive notebook code\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt # this lets you draw inline pictures in the notebooks\n",
    "import pylab # this allows you to control figure size \n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0) # this controls figure size in the notebook\n",
    "\n",
    "input_image=cv2.imread(r\"me.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc00ff8c",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "b8PY3kZ63fWO"
   },
   "source": [
    "## Basic manipulations\n",
    "\n",
    "Rotate, flip... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c80e8a2",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "4LHzdNvt3fWP"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m flipped_code_0\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mflip(input_image,\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# vertical flip\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(flipped_code_0)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "flipped_code_0=cv2.flip(input_image,0) # vertical flip\n",
    "plt.imshow(flipped_code_0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f6d5dbe",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "9SOq_oD-3fWR"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m flipped_code_1\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mflip(input_image,\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# horizontal flip\u001b[39;00m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(flipped_code_1)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "flipped_code_1=cv2.flip(input_image,1) # horizontal flip\n",
    "plt.imshow(flipped_code_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4df86cc7",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "7zapvC1p3fWU"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transposed\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose(input_image)\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(transposed)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "transposed=cv2.transpose(input_image)\n",
    "plt.imshow(transposed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eb80fa",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "n8yTtUGq3fWX"
   },
   "source": [
    "## Minimum, maximum\n",
    "\n",
    "To find the min or max of a matrix, you can use minMaxLoc. This takes a single channel image (it doesn't make much sense to take the max of a 3 channel image). So in the next code snippet you see a for loop, using python style image slicing, to look at each channel of the input image separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c202ec85",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "S7nLP0QL3fWY"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m    min_value, max_value, min_location, max_location\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mminMaxLoc(input_image[:,:,i])\n\u001b[1;32m      3\u001b[0m    \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is at \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, and max \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is at \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(min_value, min_location, max_value, max_location))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(0,3):\n",
    "   min_value, max_value, min_location, max_location=cv2.minMaxLoc(input_image[:,:,i])\n",
    "   print(\"min {} is at {}, and max {} is at {}\".format(min_value, min_location, max_value, max_location))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d30d484",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "qF_AsupK3fWa"
   },
   "source": [
    "## Arithmetic operations on images\n",
    "\n",
    "OpenCV has a lot of functions for doing mathematics on images. Some of these have \"analogous\" numpy alternatives, but it is nearly always better to use the OpenCV version. The reason for this that OpenCV is designed to work on images and so handles overflow better (OpenCV add, for example, truncates to 255 if the datatype is image-like and 8 bit; Numpy's alternative wraps around).\n",
    "\n",
    "Useful arithmetic operations include add and addWeighted, which combine two images that are the same size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61dfabe6",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "Gg5M59Lt3fWa"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#First create an image the same size as our input\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m blank_image \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mzeros((input_image\u001b[38;5;241m.\u001b[39mshape), np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m      4\u001b[0m blank_image[\u001b[38;5;241m100\u001b[39m:\u001b[38;5;241m200\u001b[39m,\u001b[38;5;241m100\u001b[39m:\u001b[38;5;241m200\u001b[39m,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m; \u001b[38;5;66;03m#give it a green square\u001b[39;00m\n\u001b[1;32m      6\u001b[0m new_image\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39madd(blank_image,input_image) \u001b[38;5;66;03m# add the two images together\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#First create an image the same size as our input\n",
    "blank_image = np.zeros((input_image.shape), np.uint8)\n",
    "\n",
    "blank_image[100:200,100:200,1]=100; #give it a green square\n",
    "\n",
    "new_image=cv2.add(blank_image,input_image) # add the two images together\n",
    "\n",
    "plt.imshow(cv2.cvtColor(new_image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6833fca7",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "ke-afLFp3fWd"
   },
   "source": [
    "## Noise reduction\n",
    "Noise reduction usually involves blurring/smoothing an image using a Gaussian kernel.\n",
    "The width of the kernel determines the amount of smoothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51dbc00b",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "EyxmwP0E3fWd"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[0;32m----> 2\u001b[0m img_blur3 \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mGaussianBlur(input_image, (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39md\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39md\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[d:\u001b[38;5;241m-\u001b[39md,d:\u001b[38;5;241m-\u001b[39md]\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(cv2\u001b[38;5;241m.\u001b[39mcvtColor(img_blur3, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "d=3\n",
    "img_blur3 = cv2.GaussianBlur(input_image, (2*d+1, 2*d+1), -1)[d:-d,d:-d]\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_blur3, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea952afa",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "GjGY7Dl33fWg"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 2\u001b[0m img_blur5 \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mGaussianBlur(input_image, (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39md\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39md\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[d:\u001b[38;5;241m-\u001b[39md,d:\u001b[38;5;241m-\u001b[39md]\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(cv2\u001b[38;5;241m.\u001b[39mcvtColor(img_blur5, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "d=5\n",
    "img_blur5 = cv2.GaussianBlur(input_image, (2*d+1, 2*d+1), -1)[d:-d,d:-d]\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_blur5, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4593ef1b",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "AaJ7zd1w3fWi"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m\n\u001b[0;32m----> 2\u001b[0m img_blur15 \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mGaussianBlur(input_image, (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39md\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39md\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[d:\u001b[38;5;241m-\u001b[39md,d:\u001b[38;5;241m-\u001b[39md]\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(cv2\u001b[38;5;241m.\u001b[39mcvtColor(img_blur15, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB))\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "d=15\n",
    "img_blur15 = cv2.GaussianBlur(input_image, (2*d+1, 2*d+1), -1)[d:-d,d:-d]\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_blur15, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b96e8",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "Hp50ZT_A3fWk"
   },
   "source": [
    "## Edges\n",
    "\n",
    "Edge detection is the final image processing technique we're going to look at in this tutorial.\n",
    "\n",
    "For a lot of what we think of as \"modern\" computer vision techniques, edge detection functions as a building block. Much edge detection actually works by **convolution**, and indeed **convolutional neural networks** are absolutely the flavour of the month in some parts of computer vision. Sobel's edge detector was one of the first truly successful edge detection (enhancement) technique and that involves convolution at its core. You can read more about the background to Sobel here in the OpenCV docs [here](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_imgproc/py_gradients/py_gradients.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad7ef7d1",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "d7ceQSv13fWk"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sobelimage\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mcvtColor(input_image,cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m      3\u001b[0m sobelx \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mSobel(sobelimage,cv2\u001b[38;5;241m.\u001b[39mCV_64F,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,ksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m)\n\u001b[1;32m      4\u001b[0m sobely \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mSobel(sobelimage,cv2\u001b[38;5;241m.\u001b[39mCV_64F,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m,ksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "sobelimage=cv2.cvtColor(input_image,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sobelx = cv2.Sobel(sobelimage,cv2.CV_64F,1,0,ksize=9)\n",
    "sobely = cv2.Sobel(sobelimage,cv2.CV_64F,0,1,ksize=9)\n",
    "plt.imshow(sobelx,cmap = 'gray') \n",
    "plt.show()\n",
    "# Sobel works in x and in y, change sobelx to sobely in the olt line above to see the difference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b44e56",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "RWxFMGQe3fWm"
   },
   "source": [
    "Canny edge detection is another winnning technique - it takes two thresholds.\n",
    "The first one determines how likely Canny is to find an edge, and the second determines how likely it is to follow that edge once it's found. Investigate the effect of these thresholds by altering the values below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "005ff8f2",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "1MJQRgXL3fWn"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m th2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m \u001b[38;5;66;03m# Canny recommends threshold 2 is 3 times threshold 1 - you could try experimenting with this...\u001b[39;00m\n\u001b[1;32m      3\u001b[0m d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m \u001b[38;5;66;03m# gaussian blur\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m edgeresult\u001b[38;5;241m=\u001b[39m\u001b[43minput_image\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      6\u001b[0m edgeresult \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mGaussianBlur(edgeresult, (\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39md\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39md\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[d:\u001b[38;5;241m-\u001b[39md,d:\u001b[38;5;241m-\u001b[39md]\n\u001b[1;32m      8\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(edgeresult, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_image' is not defined"
     ]
    }
   ],
   "source": [
    "th1=30\n",
    "th2=60 # Canny recommends threshold 2 is 3 times threshold 1 - you could try experimenting with this...\n",
    "d=3 # gaussian blur\n",
    "\n",
    "edgeresult=input_image.copy()\n",
    "edgeresult = cv2.GaussianBlur(edgeresult, (2*d+1, 2*d+1), -1)[d:-d,d:-d]\n",
    "\n",
    "gray = cv2.cvtColor(edgeresult, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "edge = cv2.Canny(gray, th1, th2)\n",
    "\n",
    "edgeresult[edge != 0] = (0, 255, 0) # this takes pixels in edgeresult where edge non-zero colours them bright green\n",
    "\n",
    "plt.imshow(cv2.cvtColor(edgeresult, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d49af",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "X7HD5UmG5NY-"
   },
   "source": [
    "## Features in computer vision\n",
    "\n",
    "Features are image locations that are \"easy\" to find in the future.  Indeed, one of the early feature detection techniques Lucas-Kanade, sometimes called Kanade-Lucas-Tomasi or KLT features come from a seminal paper called \"Good features to track\".\n",
    "\n",
    "Edges find brightness discontinuities in an image, features find distinctive regions. There are a bunch of different feature detectors and these all have some characteristics in common: they should be quick to find, and things that are close in image-space are close in feature-space (that is, the feature representation of an object looks like the feature representation of objects that look like that object).\n",
    "\n",
    "There is a more in depth *features in OpenCV* set of tutorials [here](https://docs.opencv.org/master/db/d27/tutorial_py_table_of_contents_feature2d.html) and I'll link to various parts of that as appropriate: for more background though, go and work through the whole thing.\n",
    "\n",
    "<p>\n",
    " Estimated time needed: <strong>20 min</strong>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7fe8922",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "_8B7e-Rn5NY_"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# our usual set of includes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# these imports let you use opencv\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m \u001b[38;5;66;03m#opencv itself\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \u001b[38;5;66;03m# matrix manipulations\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#the following are to do with this interactive notebook code\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "\n",
    "# our usual set of includes\n",
    "# these imports let you use opencv\n",
    "import cv2 #opencv itself\n",
    "\n",
    "import numpy as np # matrix manipulations\n",
    "\n",
    "#the following are to do with this interactive notebook code\n",
    "%matplotlib inline \n",
    "from matplotlib import pyplot as plt # this lets you draw inline pictures in the notebooks\n",
    "import pylab # this allows you to control figure size \n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0) # this controls figure size in the notebook\n",
    "\n",
    "\n",
    "input_image=cv2.imread(r\"me.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46d29a7",
   "metadata": {
    "colab_type": "text",
    "deletable": true,
    "editable": true,
    "id": "yW11cMb15NZB"
   },
   "source": [
    "## Corner detectors\n",
    "If you think of edges as being lines, then corners are an obvious choice for features as they represent the intersection of two lines. One of the earlier corner detectors was introduced by Harris, and it is still a very effective corner detector that gets used quite a lot: it's reliable and it's fast. There's a tutorial explaining how Harris works on the OpenCV site [here](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_feature2d/py_features_harris/py_features_harris.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b59a9757",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "JdU2qm635NZC"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m harris_test\u001b[38;5;241m=\u001b[39m\u001b[43minput_image\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#greyscale it\u001b[39;00m\n\u001b[1;32m      3\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(harris_test,cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_image' is not defined"
     ]
    }
   ],
   "source": [
    "harris_test=input_image.copy()\n",
    "#greyscale it\n",
    "gray = cv2.cvtColor(harris_test,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "gray = np.float32(gray)\n",
    "blocksize=4 # \n",
    "kernel_size=3 # sobel kernel: must be odd and fairly small\n",
    "\n",
    "# run the harris corner detector\n",
    "dst = cv2.cornerHarris(gray,blocksize,kernel_size,0.05) # parameters are blocksize, Sobel parameter and Harris threshold\n",
    "\n",
    "#result is dilated for marking the corners, this is visualisation related and just makes them bigger\n",
    "dst = cv2.dilate(dst,None)\n",
    "#we then plot these on the input image for visualisation purposes, using bright red\n",
    "harris_test[dst>0.01*dst.max()]=[0,0,255]\n",
    "plt.imshow(cv2.cvtColor(harris_test, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f5ca13",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "Rd8R15G45NZE",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "Properly speaking the Harris Corner detection is more like a Sobel operator - indeed it is very much like a sobel operator. It doesn't really return a set of features, instead it is a filter which gives a strong response on corner-like regions of the image. We can see this more clearly if we look at the Harris output from the cell above (dst is the Harris response, before thresholding). Well we can kind-of see. You should be able to see that there are slightly light places in the image where there are corner like features, and that there are really light parts of the image around the black and white corners of the writing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f537fff",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "7z0RTbtO5NZF"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mimshow(dst,cmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(dst,cmap = 'gray') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05cea1a",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "id": "0_6wW-nY5NZH",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Moving towards feature space\n",
    "When we consider modern feature detectors there are a few things we need to mention. What makes a good feature includes the following: \n",
    "\n",
    "* Repeatability (got to be able to find it again)\n",
    "* Distinctiveness/informativeness (features representing different things need to be different)\n",
    "* Locality (they need to be local to the image feature and not, like, the whole image)\n",
    "* Quantity (you need to be able to find enough of them for them to be properly useful)\n",
    "* Accuracy (they need to accurately locate the image feature)\n",
    "* Efficiency (they've got to be computable in reasonable time)\n",
    "\n",
    "This comes from a good survey which you can find here (and which I'd thoroughly recommend reading if you're doing feature detection work) [here](https://www.slideshare.net/AhmedOne1/survey-1-project-overview)\n",
    "\n",
    "**Note:** some of the very famous feature detectors (SIFT/SURF and so on) are around, but aren't in OpenCV by default due to patent issues. You can build them for OpenCV if you want - or you can find other implementations (David Lowe's SIFT implementation works just fine). Just google for instructions.  For the purposes of this tutorial (and to save time) we're only going to look at those which are actually in OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8da1fd68",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "editable": true,
    "id": "DXu8K_FJ5NZI"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m orbimg\u001b[38;5;241m=\u001b[39m\u001b[43minput_image\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      3\u001b[0m orb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mORB_create()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# find the keypoints with ORB\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_image' is not defined"
     ]
    }
   ],
   "source": [
    "orbimg=input_image.copy()\n",
    "\n",
    "orb = cv2.ORB_create()\n",
    "# find the keypoints with ORB\n",
    "kp = orb.detect(orbimg,None)\n",
    "# compute the descriptors with ORB\n",
    "kp, des = orb.compute(orbimg, kp)\n",
    "# draw keypoints\n",
    "cv2.drawKeypoints(orbimg,kp,orbimg)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(orbimg, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaccf48",
   "metadata": {},
   "source": [
    "# Edge Detection with OpenCV\n",
    "\n",
    "## Introduction\n",
    "Edge detection is a fundamental tool in image processing and computer vision. It helps in identifying the boundaries of objects within images by detecting discontinuities in brightness. One of the most popular methods for edge detection is the **Canny Edge Detection** algorithm.\n",
    "\n",
    "In this notebook, we will capture live video feed from a webcam and apply Canny edge detection to highlight the edges in the video frames.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "Before running the code, ensure you have the following installed:\n",
    "- Python\n",
    "- OpenCV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7031dd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Open the video feed from the webcam\u001b[39;00m\n\u001b[1;32m      4\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Open the video feed from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video stream.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame.\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Perform Canny edge detection\n",
    "    edges = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "    # Display the original frame and the edge-detected frame\n",
    "    cv2.imshow('Original', frame)\n",
    "    cv2.imshow('Edge Detection', edges)\n",
    "\n",
    "    # Break the loop when 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88aa4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c77c9e-5933-4def-993c-3e22159b1dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ff3018-5559-46cb-834a-5b7f502f6a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1827cfa8-c6d3-4c32-be3e-e41195b839f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cdebbf-d488-4b7f-9b39-5fd15d75d3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f46ed20-2bd9-45ae-b2f3-8fcada1471a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831a0761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57813345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4ffd57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fe4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893cf5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dffbb19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2de883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5620c725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
