{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thug Life Filter Project\n",
    "\n",
    "### Project Overview:\n",
    "This project applies a real-time \"Thug Life\" filter to faces detected from a webcam feed. The filter involves detecting faces using OpenCV's Haar Cascade classifier and overlaying a \"Thug Life\" mask (such as sunglasses) onto the detected faces. The process is done continuously on each frame captured from the webcam.\n",
    "\n",
    "### Steps Involved:\n",
    "\n",
    "1. **Importing Libraries**:\n",
    "   - **OpenCV (cv2)**: Used for real-time computer vision, capturing webcam video, and face detection.\n",
    "   - **NumPy**: For array manipulation.\n",
    "   - **Pillow (PIL.Image)**: Used for handling image manipulation like resizing and pasting the mask on detected faces.\n",
    "\n",
    "2. **Setting Up Resources**:\n",
    "   - **Mask Image**: The image file to be overlaid on the detected face (e.g., \"Thug Life\" sunglasses).\n",
    "   - **Haar Cascade Classifier**: A pre-trained classifier file (`haarcascade_frontalface_default.xml`) for detecting faces in the webcam feed.\n",
    "\n",
    "3. **Face Detection and Mask Application**:\n",
    "   - Faces are detected using the Haar Cascade classifier on the grayscale version of each frame.\n",
    "   - The \"Thug Life\" mask is resized to match the detected face size and is pasted over each detected face, maintaining transparency.\n",
    "   \n",
    "4. **Real-Time Video Capture**:\n",
    "   - The webcam is accessed using OpenCV, and frames are continuously captured.\n",
    "   - The filter is applied frame-by-frame using the `thug_mask` function, and the result is displayed in a window.\n",
    "   - The program listens for the ESC key press to exit the loop and stop capturing.\n",
    "\n",
    "5. **Cleanup**:\n",
    "   - After the loop exits, the webcam is released, and all OpenCV windows are closed.\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "- **Haar Cascade Classifier**: A method for detecting objects in images, used here for face detection.\n",
    "- **Pillow (PIL.Image)**: Used for image manipulation (resizing and pasting the mask onto faces).\n",
    "- **OpenCV**: Handles video capture and display, as well as face detection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries:\n",
    "- **cv2**: This is the OpenCV library for real-time computer vision and image processing tasks.\n",
    "- **numpy**: NumPy is used for array manipulation and numerical operations.\n",
    "- **PIL.Image**: This module from the Pillow library is used for image processing, allowing us to manipulate images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import cv2  # OpenCV for real-time computer vision tasks\n",
    "import numpy as np  # NumPy for array manipulation\n",
    "from PIL import Image  # PIL (Pillow) for image processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying Paths:\n",
    "- **maskPath**: Path to the image file that will be used as the mask (e.g., a 'Thug Life' sunglasses or any overlay image).\n",
    "- **harcasPath**: Path to the Haar Cascade XML file used for face detection (e.g., \"haarcascade_frontalface_default.xml\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the mask image. Replace \"your mask path\" with the actual path to the image file.\n",
    "maskPath = \"mask.png\"\n",
    "\n",
    "# Path to the Haar Cascade file for face detection. Replace \"your harcas path\" with the actual path to the Haar Cascade XML file.\n",
    "harcasPath = \"harcass.xml\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Resources:\n",
    "- **faceCascade**: This line loads the pre-trained Haar Cascade classifier used to detect faces in images.\n",
    "- **mask**: This loads the mask image (like sunglasses or any accessory) that will be placed over the detected faces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Haar Cascade classifier for face detection using the path provided.\n",
    "faceCascade = cv2.CascadeClassifier(harcasPath)\n",
    "\n",
    "# Load the mask image that will be placed on the detected faces.\n",
    "mask = Image.open(maskPath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: `thug_mask(image)`\n",
    "- **gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)**: Converts the input image to grayscale since Haar Cascades are optimized for grayscale images.\n",
    "- **faces = faceCascade.detectMultiScale(gray, 2.1)**: Detects faces in the grayscale image. The `2.1` parameter is the scale factor to adjust how much the image size is reduced at each scale.\n",
    "- **background = Image.fromarray(image)**: Converts the NumPy array (original image) to a PIL image for easier manipulation.\n",
    "- **for (x, y, w, h) in faces**: Loops through each detected face, where `x`, `y` are the top-left corner coordinates, and `w`, `h` are the width and height of the detected face.\n",
    "- **resized_mask = mask.resize((w, h), Image.ANTIALIAS)**: Resizes the mask to match the detected face dimensions using anti-aliasing for smoother resizing.\n",
    "- **background.paste(resized_mask, offset, mask=resized_mask)**: Pastes the mask over the detected face, preserving its transparency using the mask parameter.\n",
    "- **return np.asarray(background)**: Converts the modified image back to a NumPy array to display it using OpenCV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to apply the mask on faces detected in the image.\n",
    "def thug_mask(image):\n",
    "    # Convert the input image to grayscale as Haar Cascades work better on grayscale images.\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect faces in the grayscale image using the Haar Cascade classifier.\n",
    "    faces = faceCascade.detectMultiScale(gray, 2.1)\n",
    "\n",
    "    # Convert the original image from NumPy array to PIL Image.\n",
    "    background = Image.fromarray(image)\n",
    "\n",
    "    # Loop through each face detected and apply the mask.\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Resize the mask to match the size of the detected face.\n",
    "        resized_mask = mask.resize((w, h), Image.LANCZOS)\n",
    "        \n",
    "        # Set the offset (position) for where to place the mask on the background image.\n",
    "        offset = (x, y)\n",
    "        \n",
    "        # Paste the resized mask on the face in the background image.\n",
    "        # The mask is applied with its transparency preserved.\n",
    "        background.paste(resized_mask, offset, mask=resized_mask)\n",
    "    \n",
    "    # Return the final image as a NumPy array to display using OpenCV.\n",
    "    return np.asarray(background)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Capture:\n",
    "- **cap = cv2.VideoCapture(0)**: This opens the webcam for capturing live video. The `0` refers to the default camera.\n",
    "### Applying the Mask in Real-time:\n",
    "- **ret, frame = cap.read()**: Reads a single frame from the video feed. `ret` is a boolean indicating whether the frame was successfully read.\n",
    "- **if not ret**: If the frame couldn't be captured, an error message is printed, and the loop is stopped.\n",
    "- **cv2.imshow(\"Thug Life Filter\", thug_mask(frame))**: This displays the current frame with the thug mask filter applied in a window titled \"Thug Life Filter\".\n",
    "- **cv2.waitKey(1)**: Waits for 1 millisecond to check if a key is pressed.\n",
    "- **if cv2.waitKey(1) == 27**: If the ESC key (27) is pressed, the loop breaks, and the webcam feed stops.\n",
    "### Cleanup:\n",
    "- **cap.release()**: Releases the webcam so that other applications can use it.\n",
    "- **cv2.destroyAllWindows()**: Closes all OpenCV windows that were opened during the program.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-05 00:06:26.361 python[4728:149196] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "2024-10-05 00:06:27.855 python[4728:149196] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2024-10-05 00:06:27.855 python[4728:149196] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Try to apply the thug mask filter on the captured frame and display it.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 15\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThug Life Filter\u001b[39m\u001b[38;5;124m\"\u001b[39m, thug_mask(frame))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError applying filter: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m, in \u001b[0;36mthug_mask\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     22\u001b[0m     background\u001b[38;5;241m.\u001b[39mpaste(resized_mask, offset, mask\u001b[38;5;241m=\u001b[39mresized_mask)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Return the final image as a NumPy array to display using OpenCV.\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(background)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/newton-school/lib/python3.11/site-packages/PIL/Image.py:742\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 742\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRecursionError\u001b[39;00m)):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/newton-school/lib/python3.11/site-packages/PIL/Image.py:815\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    813\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     bytes_consumed, errcode, data \u001b[38;5;241m=\u001b[39m e\u001b[38;5;241m.\u001b[39mencode(bufsize)\n\u001b[1;32m    816\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m    817\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Capture video from the webcam.\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Start an infinite loop to continuously capture frames from the webcam.\n",
    "while True:\n",
    "    # Read a frame from the video feed.\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If reading the frame failed, print an error message and break the loop.\n",
    "    if not ret:\n",
    "        print(\"Failed to capture image\")\n",
    "        break\n",
    "    \n",
    "    # Try to apply the thug mask filter on the captured frame and display it.\n",
    "    try:\n",
    "        cv2.imshow(\"Thug Life Filter\", thug_mask(frame))\n",
    "    except Exception as e:\n",
    "        print(f\"Error applying filter: {e}\")\n",
    "        break\n",
    "\n",
    "    # Wait for a key press for 1 millisecond, and if the ESC key (27) is pressed, break the loop.\n",
    "    if cv2.waitKey(1) == 27:  # Press ESC to exit\n",
    "        break\n",
    "# Release the webcam and close all OpenCV windows.\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
